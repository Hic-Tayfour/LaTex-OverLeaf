\documentclass[12pt]{article}

\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{graphicx}
\usepackage{wrapfig}
\usepackage{float}
\usepackage[breaklinks]{hyperref}
\hypersetup{colorlinks=true, linkcolor=Black, citecolor=Black, filecolor=Blue, urlcolor=Blue, unicode=true}

<<init, echo=FALSE>>=
knit_hooks$set(document = function(x) {
  sub('\\usepackage[]{color}',
'\\usepackage[usenames,dvipsnames]{color}', x, fixed = TRUE)
})
opts_chunk$set(fig.path="figures/knitr-")
opts_chunk$set(fig.pos = 'H')
@

\begin{document}

\title{Análise de Regressão Logística}
\author{Hicham Tayfour}
\date{2024}

\maketitle

\begin{abstract}
    Este documento demonstra a aplicação de regressão logística para prever se um cliente de um banco será um usuário de crédito, dado seu balanço, renda e status de estudante. Usaremos R e LaTeX para integrar o código, a análise e os resultados em um único documento reprodutível.
\end{abstract}

\section{Relembrando o que já foi feito}

Vimos que \textit{Machine Learning} tem duas categorias:

\begin{itemize}
    \item \textbf{Aprendizagem supervisionada}
        \begin{itemize}
            \item Temos um $x$ e um $y$.
        \end{itemize}
    \item \textbf{Aprendizagem não supervisionada}
        \begin{itemize}
            \item Temos um $x$, mas não temos um $y$ correspondente.
        \end{itemize}
\end{itemize}

\section{Aula passada}

Estávamos tentando entender, dado a renda e idade do cliente do banco, se ele pode vir a ser um usuário de crédito. Para isso, "escondemos" parte dos dados conhecidos e criamos um modelo com dados conhecidos e depois com os dados escondidos, vemos o quanto o modelo previu certo (ou errado) dado os dados escondidos.

\section{Regressão Logística}

\subsection{Vantagens}

\begin{itemize}
    \item Muito eficaz para datasets pequenos.
\end{itemize}

\subsection{O que é um Classificador?}

Um classificador é uma função que mapeia um vetor de características para uma classe.

$$
\hat{\phi} : \mathbb{R^3} \rightarrow \{0,1\}
$$

Dado um vetor de características $x_i$:

$$
x_i = \begin{bmatrix}
    x_{i,1} = \text{balance}_i \\
    x_{i,2} = \text{income}_i \\
    x_{i,3} = \text{student}_i 
\end{bmatrix} \Rightarrow \hat{\phi}(x_i) \Rightarrow y_i \in \{0,1\}
$$

\subsection{Dados de Treinamento}

O conjunto de dados de treinamento consiste em pares $((x_i, y_i))$:

$$
(x_1,y_1), (x_2,y_2), \dots, (x_n,y_n)
$$

\begin{itemize}
    \item $x_i \in \mathbb{R^p}$
    \item $y_i \in \{0,1\}$
\end{itemitemize}

\subsection{Modelo Matemático}

O modelo da regressão logística é descrito da seguinte forma:

\begin{itemize}
    \item Vetor de parâmetros:
    $$
    \beta = \begin{bmatrix} 
        \beta_0 \\ 
        \beta_1 \\ 
        \vdots \\ 
        \beta_p 
    \end{bmatrix} \in \mathbb{R}^{(p+1)\times1}
    $$

    \item Vetor de características estendido (incluindo o termo de intercepto):
    $$
    x_i = \begin{bmatrix} 
        1 \\ 
        x_{i,1} \\ 
        \vdots \\ 
        x_{i,p} 
    \end{bmatrix} \in \mathbb{R}^{(p+1)\times1}
    $$
\end{itemize}

Assumimos que $Y_1, \cdots, Y_n$ são condicionalmente independentes, dados $\beta$ e $x$.

A função de decisão da regressão logística é dada por:

$$
\log\left(\frac{\Pr\{y_i=1|\beta, x_i\}}{1-\Pr\{y_i=1|\beta, x_i\}}\right) = \beta_0 + \beta_1 x_{i,1} + \cdots + \beta_p x_{i,p} = \beta^T x_i
$$

Onde:

\begin{itemize}
    \item $\pi_i := \Pr\{y_i = 1|\beta, x_i\}$ é a probabilidade estimada da classe 1.
\end{itemize}

Rearranjando a equação, temos:

$$
\log\left(\frac{\pi_i}{1-\pi_i}\right) = \beta^T x_i
$$

A probabilidade $\pi_i$ é então:

$$
\pi_i = \frac{1}{1 + e^{-\beta^T x_i}}
$$

Consequentemente, a probabilidade complementar $(1 - \pi_i)$ é:

$$
1 - \pi_i = \frac{e^{-\beta^T x_i}}{1 + e^{-\beta^T x_i}}
$$

\subsection{Função de Verossimilhança}

Assumimos que $Y_i | \beta, x_i \sim \text{Ber}(\pi_i)$, onde $\pi_i$ é a probabilidade de sucesso.

A verossimilhança conjunta dos dados é dada por:

$$
\Pr\{Y_1=y_1, \dots, Y_n=y_n|\beta, x_1, \dots, x_n\} = \prod_{i=1}^{n} \Pr\{Y_i=y_i|\beta, x_i\}
$$

Substituindo as probabilidades na verossimilhança, temos:

$$
\prod_{i=1}^{n} \left(\frac{1}{1 + e^{-\beta^T x_i}}\right)^{y_i} \left(\frac{e^{-\beta^T x_i}}{1 + e^{-\beta^T x_i}}\right)^{1 - y_i}
$$

\section{Código}

\subsection{Importando as Bibliotecas Necessárias}

<<import_libs, echo=TRUE>>=
library(tidyverse)
library(rsample)
library(ISLR2)
library(pROC)

str(Default)
@ 

\subsection{Gráficos}

<<plot_graphs, echo=TRUE, fig.height=4, fig.width=6>>=
par(mfrow = c(1, 3))

plot(income ~ balance, data = Default,
     col = ifelse(default == "Yes", "red", "blue"),
     pch = ifelse(default == "Yes", 3, 1), cex = 0.75,
     xlab = "Balance", ylab = "Income")

plot(balance ~ default, data = Default, col = c("blue", "red"),
     xlab = "Default", ylab = "Balance")

plot(income ~ default, data = Default, col = c("blue", "red"),
     xlab = "Default", ylab = "Income")
@ 

\subsection{Simulando os Dados}

<<simulate_data, echo=TRUE>>=
set.seed(42)

split <- initial_split(Default, prop = 0.5)

training <- training(split)
test <- testing(split)

model <- glm(default ~ balance + income + student,
             data = training,
             family = binomial)

summary(model)
@ 

\subsection{Visualizando}

Esse modelo está me dando uma probabilidade do futuro cliente, dados as características desse cliente, vai ser cliente. A partir disso, quero montar uma regra de decisão.

A regressão logística não te dá o \textit{sim ou não}, mas sim a probabilidade, dado as características, qual a probabilidade dele ser \textit{sim}. \textbf{Como eu converto essa probabilidade em um \textit{sim ou não}?}

Eu tenho uma caixinha que entra o balance, o income e se é student e sai uma probabilidade, mas eu quero a caixinha que fale sim ou não. Vamos construir esse classificador, uma simples regra de decisão, acima de $x\%$ é sim, abaixo é não. Isso é chamado de ponto de corte ou \textit{threshold}.

Qual o melhor ponto de corte? Qual o ponto que minimize o erro?

Vamos usar uma matriz ou tabela de confusão, ela mostra o que você confundiu de sim com não (ela pode vir transposta).

\begin{itemize}
    \item O valor observado nas colunas e o valor previsto nas linhas
    \begin{itemize}
        \item TN = True Negative ; FN = False Negative ; FP = False Positive ; TP = True Positive
        \item $1 - \text{Specificity} = \text{FPR} = \text{False Positive Rate} = \frac{FP}{TN+FP}$
        \item $\text{Sensitivity} = \text{TPR} = \text{True Positive Rate} = \frac{TP}{FN+TP}$
        \item FPR e TPR são medidas antagônicas
        \item No mundo ideal, FPR deve ser 0 e TPR deve ser 1
    \end{itemize}
\end{itemize}

<<threshold, echo=TRUE>>=
prob <- predict(model, newdata = test, type = "response")

threshold <- 0.5 # ponto de corte

y_hat <- ifelse(prob >= threshold, "Yes", "No")

table(Predicted = y_hat, Observed = test\$default)
@ 

\subsection{Curva ROC}

Ajuda na escolha do ponto de corte.

Receiver Operating Characteristic

<<roc_curve, echo=TRUE, fig.height=5, fig.width=7>>=

roc_rlog <- roc(test\$default, prob)

names(roc_rlog)

with(roc_rlog, thresholds[which.max(sensitivities + specificities)])

par(mfrow = c(1, 2))

plot(roc_rlog, col = "blue", grid = TRUE,
     xlab = "FPR (1 -  Specificity)",
     ylab = "TPR (Sensitivity)",
     print.thres.pattern = " %.3f",
     print.thres = threshold,
     main = "ROC", legacy.axes = TRUE, asp = FALSE, las = 1)

plot(roc_rlog, col = "blue", grid = TRUE,
     xlab = "FPR (1 -  Specificity)",
     ylab = "TPR (Sensitivity)",
     print.thres.pattern = " %.3f",
     print.thres = "best",
     main = "ROC", legacy.axes = TRUE, asp = FALSE, las = 1)

auc(roc_rlog)
@ 

\end{document}
