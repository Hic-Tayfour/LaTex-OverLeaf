\documentclass{sciposter}
\usepackage{lipsum}
\usepackage{epsfig}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{multicol}
\usepackage{graphicx,url}
\usepackage[portuges, brazil]{babel}   
\usepackage[utf8]{inputenc}

\newtheorem{Def}{Definição}

\title{Modelo de Consulta de Modelagem Preditiva}
% Título do projeto

\institute 
{Bacharelado em Economia\\
Insper - Instituto de Ensino e Pesquisa\\
São Paulo, Brasil}
% Nome e endereço da Instituição

\rightlogo[1]{logo-insper.png}  % Substitua pelo logo do Insper

\begin{document}

\conference{{\bf Modelagem Preditiva}, Curso de Economia - Insper, 2024, São Paulo, Brasil}

\maketitle

%%% Início do ambiente Multicolunas
\begin{multicols}{3}

%%% Resumo
\begin{abstract}
Este documento fornece um modelo de consulta para a eletiva Modelagem Preditiva. Ele organiza os principais conceitos e tópicos relevantes para facilitar a revisão do curso.
\end{abstract}

%%% Começa aqui

\section{Diferenças entre Erros de Treinamento e de Teste em Classificação}

Em problemas de classificação, é fundamental compreender a distinção entre os \textbf{erros de treinamento} e os \textbf{erros de teste}, pois eles fornecem insights sobre o desempenho e a capacidade de generalização de um modelo.

\subsection*{Erro de Treinamento}

\begin{itemize}
    \item \textbf{Definição}: É a taxa de erro do modelo quando avaliado nos dados utilizados para treiná-lo.
    \item \textbf{Cálculo}:
    \[
    \text{Erro de Treinamento} = \frac{\text{Nº de Previsões Erradas no Treino}}{\text{Amostra de Treinamento}}
    \]
    \item \textbf{Interpretação}: Um erro de treinamento baixo indica que o modelo aprendeu bem os padrões presentes nos dados de treinamento.
\end{itemize}

\subsection*{Erro de Teste}

\begin{itemize}
    \item \textbf{Definição}: É a taxa de erro do modelo quando avaliado em um conjunto de dados novo, não utilizado durante o treinamento.
    \item \textbf{Cálculo}:
    \[
    \text{Erro de Teste} = \frac{\text{Número de Previsões Incorretas no Teste}}{\text{Total de Amostras de Teste}}
    \]
    \item \textbf{Interpretação}: Fornece uma estimativa da capacidade do modelo de generalizar para dados não vistos.
\end{itemize}

\subsection*{Diferenças Principais}

\begin{itemize}
    \item \textbf{Generalização}:
    \begin{itemize}
        \item Erro de treinamento avalia o ajuste do modelo aos dados conhecidos.
        \item Erro de teste avalia a capacidade de generalização para novos dados.
    \end{itemize}
    \item \textbf{Overfitting e Underfitting}:
    \begin{itemize}
        \item \textbf{Overfitting}: Quando o erro de treinamento é baixo e o erro de teste é alto.
        \item \textbf{Underfitting}: Quando ambos os erros são altos.
    \end{itemize}
\end{itemize}

\subsection*{Cálculo dos Erros nos Modelos de Classificação}

Para todos os modelos de classificação mencionados, os erros são calculados comparando as predições do modelo com as classes reais nos respectivos conjuntos (treinamento ou teste).

\subsubsection*{K-Nearest Neighbors (K-NN)}

\begin{itemize}
    \item \textbf{Cálculo}:
    \begin{itemize}
        \item Para cada amostra, o modelo prediz a classe com base nos $k$ vizinhos mais próximos.
        \item Conta-se o número de vezes que a classe predita difere da classe real.
    \end{itemize}
\end{itemize}

\subsubsection*{Regressão Logística}

\begin{itemize}
    \item \textbf{Cálculo}:
    \begin{itemize}
        \item O modelo fornece probabilidades para cada classe.
        \item Aplica-se um limiar (geralmente 0,5) para definir a classe predita.
        \item Compara-se a classe predita com a classe real para calcular o erro.
    \end{itemize}
\end{itemize}

\subsubsection*{Árvores de Classificação}

\begin{itemize}
    \item \textbf{Cálculo}:
    \begin{itemize}
        \item As regras da árvore são aplicadas para predizer a classe de cada amostra.
        \item O erro é calculado pela discrepância entre as predições e as classes reais.
    \end{itemize}
\end{itemize}

\subsubsection*{Árvores de Regressão}

\begin{itemize}
    \item Embora sejam usadas principalmente para regressão, podem ser adaptadas para classificação.
    \item \textbf{Cálculo}:
    \begin{itemize}
        \item Predições contínuas são convertidas em classes (por exemplo, usando um ponto de corte).
        \item Calcula-se o erro comparando as classes preditas com as reais.
    \end{itemize}
\end{itemize}

\subsection*{Importância da Avaliação em Ambos os Conjuntos}

Avaliar o modelo em ambos os conjuntos permite identificar problemas como:

\begin{itemize}
    \item \textbf{Overfitting}: Modelo complexo demais, captura o ruído dos dados de treinamento.
    \item \textbf{Underfitting}: Modelo simples demais, não captura os padrões dos dados.
\end{itemize}

\subsection*{Métricas Complementares}

Além da taxa de erro, outras métricas podem ser utilizadas:

\begin{itemize}
    \item \textbf{Acurácia}:
    \[
    \text{Acurácia} = \frac{\text{Número de Previsões Corretas}}{\text{Total de Amostras}}
    \]
    \item \textbf{Matriz de Confusão}: Permite avaliar tipos específicos de erros.
    \item \textbf{Precisão, Revocação e F1-Score}: Úteis em casos de classes desbalanceadas.
\end{itemize}

\section{Como funciona o modelo k-NN para classificação}

O \textbf{k-Nearest Neighbors (k-NN)} é um algoritmo de aprendizado baseado em instâncias que classifica uma nova amostra com base nas classes das $k$ amostras de treinamento mais próximas em termos de distância.

\subsection{Funcionamento do Algoritmo}

\begin{enumerate}
    \item \textbf{Definição do Parâmetro $k$}:
    \begin{itemize}
        \item Escolhe-se um valor inteiro positivo $k$, que representa o número de vizinhos a serem considerados.
    \end{itemize}
    \item \textbf{Cálculo das Distâncias}:
    \begin{itemize}
        \item Para a nova amostra $\mathbf{x}_{\text{nova}}$, calcula-se a distância para cada amostra $\mathbf{x}_i$ no conjunto de treinamento.
        \item A distância Euclidiana é comumente utilizada:
        \[
        d(\mathbf{x}_{\text{nova}}, \mathbf{x}_i) = \sqrt{\sum_{j=1}^{p} (x_{\text{nova},j} - x_{i,j})^2}
        \]
    \end{itemize}
    \item \textbf{Identificação dos $k$ Vizinhos Mais Próximos}:
    \begin{itemize}
        \item Ordena-se as distâncias em ordem crescente.
        \item Seleciona-se as $k$ amostras com as menores distâncias.
    \end{itemize}
    \item \textbf{Classificação por Votação Majoritária}:
    \begin{itemize}
        \item Verifica-se a classe de cada um dos $k$ vizinhos.
        \item A classe mais frequente entre os vizinhos é atribuída à nova amostra.
    \end{itemize}
\end{enumerate}

\subsection{Escolha do Valor de $k$}

\begin{itemize}
    \item \textbf{Valores Pequenos de $k$}:
    \begin{itemize}
        \item Podem tornar o modelo sensível ao ruído nos dados.
        \item Resultam em fronteiras de decisão mais complexas.
    \end{itemize}
    \item \textbf{Valores Grandes de $k$}:
    \begin{itemize}
        \item Tornam o modelo mais generalizado.
        \item Podem incluir amostras de outras classes, prejudicando a precisão.
    \end{itemize}
    \item \textbf{Métodos para Escolher $k$}:
    \begin{itemize}
        \item Testar diferentes valores de $k$ utilizando validação cruzada.
        \item Utilizar heurísticas, como $k = \sqrt{n}$, onde $n$ é o número de amostras de treinamento.
    \end{itemize}
\end{itemize}

\subsection{Normalização dos Dados}

\begin{itemize}
    \item É importante normalizar ou padronizar os atributos para que todos tenham a mesma escala.
    \item \textbf{Normalização Min-Max}:
    \[
    x' = \frac{x - \min(x)}{\max(x) - \min(x)}
    \]
    \item \textbf{Padronização (Z-score)}:
    \[
    x' = \frac{x - \mu}{\sigma}
    \]
    Onde $\mu$ é a média e $\sigma$ é o desvio padrão do atributo.
\end{itemize}

\subsection{Cálculo da Distância}

Além da distância Euclidiana, outras métricas podem ser utilizadas:

\begin{itemize}
    \item \textbf{Distância de Manhattan}:
    \[
    d_{\text{Manhattan}}(\mathbf{x}_{\text{nova}}, \mathbf{x}_i) = \sum_{j=1}^{p} |x_{\text{nova},j} - x_{i,j}|
    \]
    \item \textbf{Distância de Minkowski}:
    \[
    d_{\text{Minkowski}}(\mathbf{x}_{\text{nova}}, \mathbf{x}_i) = \left( \sum_{j=1}^{p} |x_{\text{nova},j} - x_{i,j}|^q \right)^{1/q}
    \]
    Onde $q$ é um parâmetro ajustável.
\end{itemize}

\subsection{Vantagens e Desvantagens}

\textbf{Vantagens}:

\begin{itemize}
    \item Simplicidade e facilidade de implementação.
    \item Eficaz em casos onde a fronteira de decisão é complexa.
    \item Não faz suposições paramétricas sobre a distribuição dos dados.
\end{itemize}

\textbf{Desvantagens}:

\begin{itemize}
    \item \textbf{Custo Computacional}:
    \begin{itemize}
        \item Elevado para conjuntos de dados grandes devido ao cálculo de distâncias.
    \end{itemize}
    \item \textbf{Maldição da Dimensionalidade}:
    \begin{itemize}
        \item O desempenho pode degradar em espaços de alta dimensionalidade.
    \end{itemize}
    \item \textbf{Sensibilidade ao Ruído e Outliers}:
    \begin{itemize}
        \item Amostras atípicas podem afetar a classificação.
    \end{itemize}
\end{itemize}

\subsection{Aplicações Comuns}

\begin{itemize}
    \item \textbf{Reconhecimento de Padrões}:
    \begin{itemize}
        \item Classificação de imagens, reconhecimento de dígitos manuscritos.
    \end{itemize}
    \item \textbf{Sistemas de Recomendação}:
    \begin{itemize}
        \item Sugestão de produtos com base em preferências similares.
    \end{itemize}
    \item \textbf{Detecção de Anomalias}:
    \begin{itemize}
        \item Identificação de dados que diferem significativamente do padrão geral.
    \end{itemize}
\end{itemize}

\subsection{Exemplo Ilustrativo}

Considere um conjunto de treinamento com duas classes, A e B:

\begin{enumerate}
    \item \textbf{Nova Amostra}:
    \begin{itemize}
        \item $\mathbf{x}_{\text{nova}} = (x_1, x_2)$
    \end{itemize}
    \item \textbf{Cálculo das Distâncias}:
    \begin{itemize}
        \item Calcula-se $d(\mathbf{x}_{\text{nova}}, \mathbf{x}_i)$ para cada amostra $\mathbf{x}_i$.
    \end{itemize}
    \item \textbf{Seleção dos $k$ Vizinhos}:
    \begin{itemize}
        \item Suponha $k = 3$.
        \item Identificam-se os 3 vizinhos mais próximos.
    \end{itemize}
    \item \textbf{Votação}:
    \begin{itemize}
        \item Se os vizinhos pertencem às classes A, A e B.
        \item A classe A é atribuída à nova amostra, por maioria.
    \end{itemize}
\end{enumerate}

\section{Como é definido e treinado o modelo de regressão logística}

A \textbf{Regressão Logística} é um modelo estatístico amplamente utilizado para problemas de classificação binária. Ela estima a probabilidade de uma amostra pertencer a uma determinada classe, utilizando a função logística (sigmoide) para mapear uma combinação linear de variáveis independentes para um valor entre 0 e 1.

\subsection{Definição do Modelo}

\begin{itemize}
    \item \textbf{Variáveis e Coeficientes}:
    \begin{itemize}
        \item Seja $\mathbf{x} = (x_1, x_2, \dots, x_p)$ o vetor de atributos de uma amostra.
        \item O modelo prevê a probabilidade $P(Y=1|\mathbf{x})$ utilizando a função logística:
        \[
        P(Y=1|\mathbf{x}) = \sigma(z) = \frac{1}{1 + e^{-z}}
        \]
        Onde:
        \[
        z = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \dots + \beta_p x_p = \beta_0 + \mathbf{\beta}^\top \mathbf{x}
        \]
        \item $\beta_0$ é o intercepto e $\mathbf{\beta} = (\beta_1, \beta_2, \dots, \beta_p)$ são os coeficientes dos atributos.
    \end{itemize}
\end{itemize}

\subsection{Função de Verossimilhança}

O treinamento do modelo envolve a estimação dos parâmetros $\beta_0$ e $\mathbf{\beta}$ que maximizam a função de verossimilhança, ou equivaletemente, minimizam a função de custo.

\begin{itemize}
    \item \textbf{Função de Verossimilhança}:
    \[
    L(\beta_0, \mathbf{\beta}) = \prod_{i=1}^{n} [P(Y=1|\mathbf{x}_i)]^{y_i} [1 - P(Y=1|\mathbf{x}_i)]^{1 - y_i}
    \]
    Onde $n$ é o número de amostras no conjunto de dados.
    
    \item \textbf{Função de Custo} (Negativa da Log-Verossimilhança):
    \[
    J(\beta_0, \mathbf{\beta}) = \\
    
    - \sum_{i=1}^{n} \left[ y_i \log(P(Y=1|\mathbf{x}_i)) + (1 - y_i) \log(1 - P(Y=1|\mathbf{x}_i)) \right]
    \]
\end{itemize}

\subsection{Treinamento do Modelo}

\begin{enumerate}
    \item \textbf{Inicialização}:
    \begin{itemize}
        \item Iniciar os parâmetros $\beta_0$ e $\mathbf{\beta}$ com valores próximos de zero ou aleatórios.
    \end{itemize}
    
    \item \textbf{Otimização}:
    \begin{itemize}
        \item Utilizar algoritmos de otimização, como \textbf{Gradiente Descendente} ou \textbf{Newton-Raphson}, para minimizar a função de custo $J$.
    \end{itemize}
    
    \item \textbf{Gradiente Descendente}:
    \begin{itemize}
        \item Atualizar os parâmetros iterativamente utilizando a regra:
        \[
        \beta_j := \beta_j - \alpha \frac{\partial J}{\partial \beta_j}
        \]
        Onde $\alpha$ é a taxa de aprendizado e:
        \[
        \frac{\partial J}{\partial \beta_j} = - \sum_{i=1}^{n} (y_i - P(Y=1|\mathbf{x}_i)) x_{ij}
        \]
    \end{itemize}
    
    \item \textbf{Convergência}:
    \begin{itemize}
        \item O processo de otimização continua até que a mudança na função de custo seja menor que um limiar pré-definido.
    \end{itemize}
\end{enumerate}

\subsection{Interpretação dos Coeficientes}

\begin{itemize}
    \item Os coeficientes $\beta_j$ representam o log-odds ratio associado ao atributo $x_j$.
    \item \textbf{Odds}:
    \[
    \text{Odds} = \frac{P(Y=1|\mathbf{x})}{1 - P(Y=1|\mathbf{x})} = e^{z}
    \]
    \item \textbf{Interpretação}:
    \begin{itemize}
        \item Um aumento unitário em $x_j$ multiplica os odds por $e^{\beta_j}$.
        \item Se $\beta_j > 0$, aumenta a probabilidade de $Y=1$; se $\beta_j < 0$, diminui.
    \end{itemize}
\end{itemize}

\subsection{Predição}

\begin{itemize}
    \item Para uma nova amostra $\mathbf{x}_{\text{nova}}$, calcula-se:
    \[
    P(Y=1|\mathbf{x}_{\text{nova}}) = \frac{1}{1 + e^{-(\beta_0 + \mathbf{\beta}^\top \mathbf{x}_{\text{nova}})}}
    \]
    \item A classe predita é determinada pelo limiar $\tau$:
    \[
    \hat{y} = 
    \begin{cases}
        1, & \text{se } P(Y=1|\mathbf{x}_{\text{nova}}) \geq \tau \\
        0, & \text{se } P(Y=1|\mathbf{x}_{\text{nova}}) < \tau
    \end{cases}
    \]
    \item Comumente, $\tau = 0{,}5$, mas pode ser ajustado conforme a aplicação.
\end{itemize}

\subsection{Regularização}

Para evitar overfitting, técnicas de regularização são aplicadas adicionando penalidades à função de custo.

\begin{itemize}
    \item \textbf{Regularização Lasso (L1)}:
    \[
    J_{\text{reg}} = J + \lambda \sum_{j=1}^{p} |\beta_j|
    \]
    \item \textbf{Regularização Ridge (L2)}:
    \[
    J_{\text{reg}} = J + \lambda \sum_{j=1}^{p} \beta_j^2
    \]
    \item Onde $\lambda$ é o hiperparâmetro de regularização que controla a força da penalização.
\end{itemize}

\subsection{Avaliação do Modelo}

\begin{itemize}
    \item \textbf{Matriz de Confusão}: Tabela que resume as predições corretas e incorretas.
    \item \textbf{Acurácia}:
    \[
    \text{Acurácia} = \frac{\text{VP} + \text{VN}}{\text{VP} + \text{VN} + \text{FP} + \text{FN}}
    \]
    \item \textbf{Curva ROC e AUC}: Avaliam a performance do modelo em diferentes limiares $\tau$.
    \item \textbf{Precisão, Revocação e F1-Score}: Métricas adicionais para avaliar o desempenho, especialmente em conjuntos de dados desbalanceados.
\end{itemize}

\subsection{Assunções do Modelo}

\begin{itemize}
    \item \textbf{Independência dos Atributos}: Os atributos são linearmente relacionados ao log-odds.
    \item \textbf{Ausência de Multicolinearidade}: A forte correlação entre atributos pode afetar a estabilidade dos coeficientes.
    \item \textbf{Tamanho da Amostra Adequado}: Necessário para estimar corretamente os parâmetros do modelo.
\end{itemize}

\subsection{Vantagens e Desvantagens}

\textbf{Vantagens}:

\begin{itemize}
    \item Simplicidade e facilidade de interpretação.
    \item Eficiente para classificação binária.
    \item Possibilidade de incorporar regularização para evitar overfitting.
\end{itemize}

\textbf{Desvantagens}:

\begin{itemize}
    \item Assume uma relação linear entre os atributos e o log-odds, o que pode não ser verdadeiro para todos os problemas.
    \item Não é adequada para problemas não lineares sem transformações nos atributos.
    \item Sensível a outliers, que podem influenciar os coeficientes do modelo.
\end{itemize}

\subsection{Extensões do Modelo}

\begin{itemize}
    \item \textbf{Regressão Logística Multinomial}: Extensão para problemas de classificação com mais de duas classes.
    \item \textbf{Regressão Logística Ordinal}: Para classes com uma ordem natural.
    \item \textbf{Modelos Generalizados Aditivos}: Incorporam termos não lineares para capturar relações mais complexas entre os atributos e a variável alvo.
\end{itemize}

\section{Como é feita a previsão no modelo de regressão logística}

A previsão no modelo de \textbf{Regressão Logística} envolve calcular a probabilidade de uma amostra pertencer a uma classe com base nos atributos fornecidos e nos coeficientes do modelo treinado. O modelo utiliza a função logística para transformar uma combinação linear dos atributos em uma probabilidade entre 0 e 1.

\subsection{Cálculo da Probabilidade}

\begin{itemize}
    \item Para uma nova amostra $\mathbf{x}_{\text{nova}} = (x_1, x_2, \dots, x_p)$, a previsão é feita calculando a probabilidade $P(Y=1|\mathbf{x}_{\text{nova}})$ da amostra pertencer à classe $Y=1$.
    \item O modelo calcula a combinação linear dos atributos:
    \[
    z = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \dots + \beta_p x_p
    \]
    \item A probabilidade é então obtida aplicando a função logística (sigmoide):
    \[
    P(Y=1|\mathbf{x}_{\text{nova}}) = \sigma(z) = \frac{1}{1 + e^{-z}}
    \]
\end{itemize}

\subsection{Tomada de Decisão: Definição da Classe Predita}

\begin{itemize}
    \item Após o cálculo da probabilidade, uma regra de decisão é aplicada para determinar a classe predita.
    \item A classe predita, $\hat{y}$, é determinada comparando a probabilidade com um limiar (threshold) $\tau$:
    \[
    \hat{y} = 
    \begin{cases}
        1, & \text{se } P(Y=1|\mathbf{x}_{\text{nova}}) \geq \tau \\
        0, & \text{se } P(Y=1|\mathbf{x}_{\text{nova}}) < \tau
    \end{cases}
    \]
    \item O valor mais comum para o limiar é $\tau = 0{,}5$, significando que o modelo prediz a classe $Y=1$ se a probabilidade calculada for maior ou igual a 0,5, e a classe $Y=0$ caso contrário.
\end{itemize}

\subsection{Ajuste do Limiar $\tau$}

\begin{itemize}
    \item O limiar $\tau$ pode ser ajustado dependendo das necessidades do problema.
    \item Em problemas com classes desbalanceadas ou onde os custos de erros são diferentes, valores de $\tau$ diferentes de 0,5 podem ser mais apropriados.
    \item Por exemplo:
    \begin{itemize}
        \item Para aumentar a sensibilidade (detecção de verdadeiros positivos), pode-se reduzir o valor de $\tau$.
        \item Para aumentar a especificidade (detecção de verdadeiros negativos), pode-se aumentar o valor de $\tau$.
    \end{itemize}
\end{itemize}

\subsection{Exemplo de Predição}

\begin{itemize}
    \item Suponha um modelo treinado com os seguintes coeficientes: $\beta_0 = -1$, $\beta_1 = 2$, $\beta_2 = -0{,}5$.
    \item Para uma nova amostra $\mathbf{x}_{\text{nova}} = (1, 3)$:
    \[
    z = -1 + 2 \times 1 - 0{,}5 \times 3 = 0{,}5
    \]
    \item A probabilidade é então:
    \[
    P(Y=1|\mathbf{x}_{\text{nova}}) = \frac{1}{1 + e^{-0{,}5}} \approx 0{,}622
    \]
    \item Se $\tau = 0{,}5$, a classe predita seria $Y=1$, pois $P(Y=1|\mathbf{x}_{\text{nova}}) > 0{,}5$.
\end{itemize}

\subsection{Vantagens da Previsão Probabilística}

\begin{itemize}
    \item \textbf{Interpretação Direta}: A previsão em forma de probabilidade permite uma interpretação clara da incerteza associada à predição.
    \item \textbf{Flexibilidade}: Ao ajustar o limiar $\tau$, é possível adaptar o modelo para diferentes necessidades, como maximizar a sensibilidade ou a especificidade.
    \item \textbf{Aplicações Amplas}: Modelos de regressão logística com previsão probabilística são amplamente utilizados em problemas de classificação binária, como diagnóstico médico e análise de crédito.
\end{itemize}

\section{Como estabelecer um "threshold" (ponto de corte) em classificadores probabilísticos}

Quando um modelo de classificação fornece probabilidades para as classes, como a \textbf{Regressão Logística}, é necessário definir um \textbf{threshold} (ponto de corte) para converter essas probabilidades em uma regra de classificação binária. O threshold é o valor a partir do qual uma probabilidade prevista é convertida em uma classe.

\subsection{Definição do Threshold}

\begin{itemize}
    \item O valor mais comumente utilizado para o threshold é $\tau = 0{,}5$, significando que se a probabilidade prevista for maior ou igual a 0,5, a classe prevista será $Y=1$; caso contrário, será $Y=0$.
    \item No entanto, esse valor pode ser ajustado dependendo do problema e das características dos dados, especialmente quando as classes estão desbalanceadas ou quando o custo de erros é assimétrico.
\end{itemize}

\subsection{Impacto da Escolha do Threshold}

\begin{itemize}
    \item \textbf{Sensibilidade vs. Especificidade}:
    \begin{itemize}
        \item A escolha do threshold afeta a \textbf{sensibilidade} (taxa de verdadeiros positivos) e a \textbf{especificidade} (taxa de verdadeiros negativos) do modelo.
        \item \textbf{Thresholds Baixos} ($\tau < 0{,}5$):
        \begin{itemize}
            \item Aumentam a sensibilidade, detectando mais verdadeiros positivos.
            \item No entanto, aumentam a taxa de falsos positivos (classificando erroneamente $Y=0$ como $Y=1$).
        \end{itemize}
        \item \textbf{Thresholds Altos} ($\tau > 0{,}5$):
        \begin{itemize}
            \item Aumentam a especificidade, identificando mais verdadeiros negativos.
            \item Contudo, aumentam a taxa de falsos negativos (classificando erroneamente $Y=1$ como $Y=0$).
        \end{itemize}
    \end{itemize}
\end{itemize}

\subsection{Como Escolher o Threshold Ideal}

A escolha do threshold ideal pode ser feita de várias maneiras, dependendo do objetivo do problema e do tipo de erro que se deseja minimizar.

\subsubsection{Curva ROC e AUC}

\begin{itemize}
    \item A \textbf{Curva ROC (Receiver Operating Characteristic)} é uma ferramenta importante para avaliar o desempenho de um classificador em diferentes thresholds.
    \item A curva ROC plota a \textbf{sensibilidade} (taxa de verdadeiros positivos) contra o complemento da \textbf{especificidade} (taxa de falsos positivos) para diferentes valores de $\tau$.
    \item A \textbf{Área Sob a Curva (AUC - Area Under the Curve)} fornece uma métrica de desempenho geral do modelo.
    \begin{itemize}
        \item Um valor de AUC próximo de 1 indica um bom desempenho do classificador.
        \item A curva pode ser utilizada para identificar um threshold que equilibre bem sensibilidade e especificidade.
    \end{itemize}
\end{itemize}

\subsubsection{Maximização do F1-Score}

\begin{itemize}
    \item O \textbf{F1-Score} é a média harmônica entre precisão e sensibilidade, sendo uma métrica útil em problemas com classes desbalanceadas.
    \item O threshold pode ser escolhido de forma a maximizar o F1-Score, equilibrando a proporção de verdadeiros positivos e a precisão.
\end{itemize}

\subsubsection{Consideração de Custos Assimétricos}

\begin{itemize}
    \item Em certos problemas, os custos de falsos positivos e falsos negativos podem ser diferentes. Por exemplo:
    \begin{itemize}
        \item Em diagnósticos médicos, um falso negativo (não detectar uma doença) pode ser mais grave do que um falso positivo (diagnosticar erroneamente uma doença).
        \item Em tais casos, o threshold pode ser ajustado para minimizar o erro mais custoso.
    \end{itemize}
\end{itemize}

\subsection{Exemplo de Estabelecimento do Threshold}

\begin{itemize}
    \item Suponha que um modelo de regressão logística preveja uma probabilidade de 0{,}7 para uma amostra.
    \item Com o threshold padrão $\tau = 0{,}5$, a classe prevista será $Y=1$.
    \item Se o threshold for ajustado para $\tau = 0{,}8$ (por exemplo, para aumentar a precisão), a mesma amostra seria classificada como $Y=0$, já que $0{,}7 < 0{,}8$.
\end{itemize}

\subsection{Conclusão}

A escolha do threshold é uma etapa crítica na construção de classificadores probabilísticos. O valor do threshold deve ser ajustado conforme os objetivos do problema e o tipo de erro que se deseja minimizar. Ferramentas como a curva ROC, o F1-Score e considerações sobre os custos assimétricos de erro são essenciais para a definição de um threshold ideal.

\section{Matriz de confusão, especificidade, sensibilidade e interpretação da curva ROC e AUC}

A \textbf{matriz de confusão} é uma ferramenta que resume o desempenho de um modelo de classificação, comparando as predições feitas com as classes reais. A partir dessa matriz, métricas como \textbf{especificidade}, \textbf{sensibilidade}, e a \textbf{curva ROC} podem ser derivadas para avaliar a performance do modelo.

\subsection{Matriz de Confusão}

A matriz de confusão é uma tabela que organiza os acertos e erros do modelo em relação às verdadeiras classes das amostras. Para problemas de classificação binária, a matriz tem a seguinte estrutura:

\begin{center}
\begin{tabular}{|c|c|c|}
\hline
 & \textbf{Classe Predita: $Y=1$} & \textbf{Classe Predita: $Y=0$} \\
\hline
\textbf{Classe Real: $Y=1$} & Verdadeiro Positivo (VP) & Falso Negativo (FN) \\
\hline
\textbf{Classe Real: $Y=0$} & Falso Positivo (FP) & Verdadeiro Negativo (VN) \\
\hline
\end{tabular}
\end{center}

\subsection{Cálculo da Especificidade e Sensibilidade}

A partir da matriz de confusão, várias métricas podem ser calculadas para avaliar o desempenho do modelo.

\subsubsection{Sensibilidade (Recall ou True Positive Rate - TPR)}

A \textbf{sensibilidade} mede a capacidade do modelo de identificar corretamente as amostras da classe positiva ($Y=1$).

\[
\text{Sensibilidade} = \frac{VP}{VP + FN}
\]

\begin{itemize}
    \item Indica a proporção de verdadeiros positivos corretamente identificados pelo modelo.
    \item Sensibilidade alta significa que poucos exemplos positivos estão sendo classificados como negativos.
\end{itemize}

\subsubsection{Especificidade (True Negative Rate - TNR)}

A \textbf{especificidade} mede a capacidade do modelo de identificar corretamente as amostras da classe negativa ($Y=0$).

\[
\text{Especificidade} = \frac{VN}{VN + FP}
\]

\begin{itemize}
    \item Indica a proporção de verdadeiros negativos corretamente identificados pelo modelo.
    \item Especificidade alta significa que poucos exemplos negativos estão sendo classificados como positivos.
\end{itemize}

\subsubsection{Outras Métricas Derivadas}

\begin{itemize}
    \item \textbf{Precisão (Precision)}:
    \[
    \text{Precisão} = \frac{VP}{VP + FP}
    \]
    Mede a proporção de verdadeiros positivos entre todas as predições positivas.
    
    \item \textbf{Acurácia (Accuracy)}:
    \[
    \text{Acurácia} = \frac{VP + VN}{VP + FN + FP + VN}
    \]
    Mede a proporção de predições corretas, considerando todas as classes.
    
    \item \textbf{F1-Score}:
    \[
    F1 = 2 \times \frac{\text{Precisão} \times \text{Sensibilidade}}{\text{Precisão} + \text{Sensibilidade}}
    \]
    Uma métrica que combina precisão e sensibilidade, especialmente útil em problemas com classes desbalanceadas.
\end{itemize}

\subsection{Curva ROC e Interpretação da AUC}

\subsubsection{Curva ROC (Receiver Operating Characteristic)}

A \textbf{curva ROC} é uma representação gráfica do desempenho de um classificador ao variar o threshold (ponto de corte) que separa as classes. Ela plota a \textbf{taxa de verdadeiros positivos} (sensibilidade) contra a \textbf{taxa de falsos positivos} (1 - especificidade) para diferentes valores de threshold.

\begin{itemize}
    \item A curva ROC mostra o trade-off entre sensibilidade e especificidade para diferentes thresholds.
    \item Classificadores melhores terão curvas ROC mais próximas do canto superior esquerdo, indicando uma alta sensibilidade e uma baixa taxa de falsos positivos.
\end{itemize}

\subsubsection{AUC (Área Sob a Curva)}

\textbf{AUC} é a área sob a curva ROC e fornece uma métrica quantitativa do desempenho do classificador.

\begin{itemize}
    \item \textbf{Interpretação da AUC}:
    \begin{itemize}
        \item Um valor de \textbf{AUC = 1} indica um classificador perfeito.
        \item Um valor de \textbf{AUC = 0{,}5} indica um classificador aleatório.
        \item Quanto maior a AUC, melhor o classificador consegue distinguir entre as classes $Y=1$ e $Y=0$.
    \end{itemize}
    \item A AUC fornece uma métrica independente do threshold, permitindo a comparação de classificadores em diferentes configurações.
\end{itemize}

\subsection{Exemplo de Interpretação}

\begin{itemize}
    \item Suponha que um modelo preditivo tenha os seguintes resultados para um conjunto de teste:
    \[
    \text{VP} = 80, \quad \text{FN} = 20, \quad \text{FP} = 10, \quad \text{VN} = 90
    \]
    \item \textbf{Sensibilidade}:
    \[
    \text{Sensibilidade} = \frac{80}{80 + 20} = 0{,}80
    \]
    \item \textbf{Especificidade}:
    \[
    \text{Especificidade} = \frac{90}{90 + 10} = 0{,}90
    \]
    \item \textbf{Precisão}:
    \[
    \text{Precisão} = \frac{80}{80 + 10} = 0{,}89
    \]
    \item Esses valores indicam que o modelo possui uma boa capacidade de detectar positivos (alta sensibilidade) e minimizar falsos positivos (alta especificidade), com uma precisão relativamente alta.
\end{itemize}

\subsection{Conclusão}

A matriz de confusão e as métricas derivadas como sensibilidade, especificidade, e AUC são ferramentas essenciais para avaliar o desempenho de classificadores. A curva ROC permite visualizar o desempenho do modelo para diferentes thresholds, enquanto a AUC fornece uma métrica robusta para comparar classificadores.

\section{Como interpretar uma árvore de classificação ou de regressão}

Uma \textbf{árvore de decisão} é um modelo de aprendizado supervisionado que pode ser usado tanto para problemas de \textbf{classificação} quanto de \textbf{regressão}. Uma árvore é composta por nós, ramos e folhas que, em conjunto, realizam sucessivas partições do espaço de atributos, conduzindo a predições para a variável alvo. A interpretação de uma árvore envolve compreender a estrutura dessas divisões e como elas levam à predição.

\subsection{Componentes de uma Árvore de Decisão}

\begin{itemize}
    \item \textbf{Nós Internos}:
    \begin{itemize}
        \item Cada nó interno representa uma condição de decisão baseada em um atributo.
        \item Para árvores de classificação, a condição pode ser uma comparação como \texttt{atributo $<$ valor}.
        \item Para árvores de regressão, a decisão também envolve comparações contínuas, mas o valor previsto é numérico.
    \end{itemize}
    
    \item \textbf{Ramos}:
    \begin{itemize}
        \item Conectam nós internos e representam os diferentes resultados possíveis da condição de decisão.
        \item Cada ramo leva a um novo nó ou a uma folha.
    \end{itemize}
    
    \item \textbf{Folhas}:
    \begin{itemize}
        \item As folhas representam as classes (no caso de classificação) ou valores preditos (no caso de regressão).
        \item Uma folha contém a resposta final após a série de decisões.
    \end{itemize}
\end{itemize}

\subsection{Interpretação de uma Árvore de Classificação}

Para uma árvore de classificação, a interpretação passa por entender como os nós de decisão particionam o espaço de atributos para separar as amostras em classes distintas.

\begin{itemize}
    \item \textbf{Raiz da Árvore}:
    \begin{itemize}
        \item A árvore começa no nó raiz, onde ocorre a primeira decisão baseada em um atributo. Este é geralmente o atributo mais informativo, escolhido por medidas como o \textbf{Ganho de Informação} ou o \textbf{Índice de Gini}.
    \end{itemize}
    
    \item \textbf{Nós Internos}:
    \begin{itemize}
        \item Cada nó interno representa uma nova partição do conjunto de dados, baseada em uma condição sobre um atributo.
        \item A cada nó, o espaço de decisão é dividido em duas ou mais sub-regiões.
        \item A interpretação envolve seguir os caminhos possíveis até atingir uma folha.
    \end{itemize}
    
    \item \textbf{Folhas}:
    \begin{itemize}
        \item Cada folha corresponde a uma classe final, resultado das decisões anteriores.
        \item A classe atribuída à folha é a que contém a maioria das amostras ou a probabilidade maior de pertencimento àquela classe.
    \end{itemize}
\end{itemize}

\subsubsection{Exemplo de Interpretação de uma Árvore de Classificação}

Suponha uma árvore de classificação para prever se uma pessoa aprova ou não um crédito com base em dois atributos: \textbf{renda} e \textbf{idade}.

\begin{itemize}
    \item O nó raiz pode ser uma condição como \texttt{renda $>$ 50.000}.
    \item Se a condição for verdadeira, o próximo nó pode ser \texttt{idade $<$ 30}, e o caminho leva a uma folha que prediz \texttt{aprovado}.
    \item Se a condição inicial for falsa, o modelo pode prever \texttt{não aprovado}.
\end{itemize}

\subsection{Interpretação de uma Árvore de Regressão}

Para uma árvore de regressão, a interpretação é semelhante à de uma árvore de classificação, mas com a diferença de que as folhas contêm valores numéricos ao invés de classes.

\begin{itemize}
    \item \textbf{Nós Internos}:
    \begin{itemize}
        \item Os nós internos ainda particionam os dados com base em condições sobre os atributos, mas o objetivo é prever um valor contínuo.
        \item A decisão de particionar em um determinado ponto é baseada na minimização da soma dos erros quadráticos ou outra métrica de ajuste.
    \end{itemize}
    
    \item \textbf{Folhas}:
    \begin{itemize}
        \item Cada folha contém o valor médio das amostras presentes naquela região ou uma predição numérica específica.
    \end{itemize}
\end{itemize}

\subsubsection{Exemplo de Interpretação de uma Árvore de Regressão}

Suponha uma árvore de regressão usada para prever o preço de uma casa com base no número de quartos e na área total.

\begin{itemize}
    \item O nó raiz pode ser a condição \texttt{número de quartos $>$ 3}.
    \item Se a condição for verdadeira, o próximo nó pode ser \texttt{área total $>$ 200 m²}, levando a uma folha que prevê o preço médio de $500.000$ reais.
    \item Se a condição inicial for falsa, o valor previsto na folha pode ser $300.000$ reais.
\end{itemize}

\subsection{Importância dos Atributos}

A árvore também pode ser interpretada em termos da \textbf{importância dos atributos}, que indica quais variáveis têm maior influência na predição final. Isso é medido pela quantidade de redução de impureza (para árvores de classificação) ou pela redução do erro (para árvores de regressão) que cada atributo proporciona.

\subsection{Vantagens e Desvantagens das Árvores de Decisão}

\textbf{Vantagens}:
\begin{itemize}
    \item Facilidade de interpretação, pois as regras de decisão são claras e podem ser facilmente visualizadas.
    \item Não requerem normalização ou padronização dos dados.
    \item Podem lidar com dados categóricos e numéricos simultaneamente.
\end{itemize}

\textbf{Desvantagens}:
\begin{itemize}
    \item Árvores de decisão são propensas ao \textbf{overfitting}, especialmente quando a árvore cresce demais.
    \item Pequenas variações nos dados podem resultar em árvores completamente diferentes (alta variância).
    \item Árvores grandes podem se tornar difíceis de interpretar.
\end{itemize}

\subsection{Conclusão}

A interpretação de árvores de decisão, seja para classificação ou regressão, envolve seguir as condições de decisão ao longo dos nós até atingir uma folha, onde a predição final é feita. A simplicidade de interpretação é uma das maiores vantagens desse modelo, mas é importante estar atento ao risco de overfitting e à sensibilidade da árvore a variações nos dados.

\section{Cálculo dos erros quadráticos médios de treinamento e de teste em problemas de regressão}

Em problemas de regressão, o \textbf{Erro Quadrático Médio (MSE - Mean Squared Error)} é uma métrica amplamente utilizada para avaliar o desempenho de um modelo. O MSE mede a diferença média entre os valores preditos pelo modelo e os valores reais, tanto no conjunto de \textbf{treinamento} quanto no de \textbf{teste}. Ele é calculado como a média dos quadrados das diferenças entre as predições e os valores reais.

\subsection{Erro Quadrático Médio (MSE)}

O MSE é calculado pela fórmula:

\[
\text{MSE} = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2
\]

Onde:
\begin{itemize}
    \item $n$ é o número de amostras no conjunto de dados.
    \item $y_i$ é o valor real da variável de interesse para a $i$-ésima amostra.
    \item $\hat{y}_i$ é o valor predito pelo modelo para a $i$-ésima amostra.
\end{itemize}

\subsection{MSE no Conjunto de Treinamento}

O \textbf{MSE de treinamento} avalia o desempenho do modelo nos dados utilizados para ajustá-lo. Um MSE de treinamento baixo indica que o modelo está bem ajustado aos dados de treinamento, ou seja, as predições estão próximas dos valores reais.

\[
\text{MSE}_{\text{treinamento}} = \frac{1}{n_{\text{train}}} \sum_{i=1}^{n_{\text{train}}} (y_i - \hat{y}_i)^2
\]

Onde $n_{\text{train}}$ é o número de amostras no conjunto de treinamento.

\subsection{MSE no Conjunto de Teste}

O \textbf{MSE de teste} avalia o desempenho do modelo em um conjunto de dados que não foi usado para treiná-lo, o que nos dá uma estimativa de como o modelo generaliza para dados não vistos.

\[
\text{MSE}_{\text{teste}} = \frac{1}{n_{\text{test}}} \sum_{i=1}^{n_{\text{test}}} (y_i - \hat{y}_i)^2
\]

Onde $n_{\text{test}}$ é o número de amostras no conjunto de teste.

\subsection{Interpretação dos Erros Quadráticos Médios}

\begin{itemize}
    \item Um \textbf{MSE de treinamento} muito baixo pode indicar \textbf{overfitting}, onde o modelo ajusta-se muito bem aos dados de treinamento, mas pode não generalizar bem para novos dados.
    \item Um \textbf{MSE de teste} significativamente maior que o de treinamento também é um sinal de \textbf{overfitting}, pois indica que o modelo não consegue generalizar adequadamente para dados novos.
    \item Por outro lado, se o \textbf{MSE de treinamento} e o \textbf{MSE de teste} forem ambos altos, isso pode indicar \textbf{underfitting}, ou seja, o modelo é muito simples e não captura bem os padrões nos dados.
\end{itemize}

\subsection{Exemplo de Cálculo do MSE}

Suponha que temos as seguintes predições e valores reais para 3 amostras no conjunto de teste:

\[
\begin{array}{|c|c|c|}
\hline
\text{Amostra} & \text{Valor Real} & \text{Valor Predito} \\
\hline
1 & 5 & 4.8 \\
2 & 10 & 9.5 \\
3 & 15 & 16.2 \\
\hline
\end{array}
\]

O MSE é calculado como:

\[
\text{MSE}_{\text{teste}} = \frac{1}{3} \left[(5 - 4.8)^2 + (10 - 9.5)^2 + (15 - 16.2)^2 \right]
\]

\[
= \frac{1}{3} \left[ 0.04 + 0.25 + 1.44 \right] = \frac{1}{3} \times 1.73 = 0.577
\]

O MSE de teste para este conjunto de amostras seria 0.577.

\subsection{Vantagens e Limitações do MSE}

\textbf{Vantagens}:
\begin{itemize}
    \item O MSE penaliza grandes erros mais fortemente do que erros pequenos, o que pode ser útil em muitos cenários de regressão.
    \item É fácil de interpretar em termos de unidades quadradas da variável predita.
\end{itemize}

\textbf{Limitações}:
\begin{itemize}
    \item Por penalizar erros grandes mais severamente, o MSE é sensível a \textbf{outliers}, o que pode distorcer a avaliação do modelo.
    \item Como é calculado em termos quadrados, o MSE pode ser difícil de interpretar diretamente em problemas com variáveis que têm diferentes escalas.
\end{itemize}

\subsection{Conclusão}

O \textbf{Erro Quadrático Médio (MSE)} é uma métrica fundamental para avaliar a qualidade de modelos de regressão, tanto em termos de ajuste (treinamento) quanto de generalização (teste). Um bom modelo terá um MSE de teste próximo ao de treinamento, indicando que ele generaliza bem para novos dados. No entanto, é importante ficar atento ao risco de overfitting, caso o MSE de treinamento seja muito baixo e o de teste muito alto.


\end{multicols}

\end{document}
